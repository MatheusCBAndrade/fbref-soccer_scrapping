{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O CÓDIGO COMPLETO E FUNCIONAL ESTÁ ABAIXO DAS TENTATIVAS TESTES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testando etapa 1 com apenas 1 url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Etapa 1 apenas para 1 url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://fbref.com/en/comps/24/2022/schedule/2022-Serie-A-Scores-and-Fixtures\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "table = soup.find('div', {'id': 'div_sched_2022_24_1'}).find('table', {'id': 'sched_2022_24_1'})\n",
    "tbody = table.find('tbody')\n",
    "\n",
    "# Dicionário para armazenar as informações\n",
    "data = {\n",
    "    'date': [],\n",
    "    'team1': [],\n",
    "    'team1_xg': [],\n",
    "    'team2': [],\n",
    "    'team2_xg': [],\n",
    "    'match_report_url': []\n",
    "}\n",
    "\n",
    "for row in tbody.find_all('tr'):\n",
    "    # Verifique se a linha contém dados\n",
    "    date_cell = row.find('td', {'data-stat': 'date'})\n",
    "    if date_cell and date_cell.find('a'):  # Verifique se a célula 'date' contém um link\n",
    "        data['date'].append(date_cell.text)\n",
    "        data['team1'].append(row.find('td', {'data-stat': 'home_team'}).text)\n",
    "        data['team1_xg'].append(row.find('td', {'data-stat': 'home_xg'}).text)\n",
    "        data['team2'].append(row.find('td', {'data-stat': 'away_team'}).text)\n",
    "        data['team2_xg'].append(row.find('td', {'data-stat': 'away_xg'}).text)\n",
    "        match_report_cell = row.find('td', {'data-stat': 'match_report'})\n",
    "        data['match_report_url'].append(\"https://fbref.com\" + match_report_cell.find('a')['href'])\n",
    "\n",
    "# Converta o dicionário em um DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "print(df.shape)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(380, 6)\n",
      "         date             team1 team1_xg          team2 team2_xg  \\\n",
      "0  2022-04-09        Fluminense      1.6         Santos      0.1   \n",
      "1  2022-04-09    Atl Goianiense      1.4       Flamengo      1.2   \n",
      "2  2022-04-10          Coritiba      1.7          Goiás      0.4   \n",
      "3  2022-04-10  Atlético Mineiro      1.9  Internacional      0.6   \n",
      "4  2022-04-10     Botafogo (RJ)      1.5    Corinthians      2.1   \n",
      "\n",
      "                                    match_report_url  \n",
      "0  https://fbref.com/en/matches/9a0d7bad/Fluminen...  \n",
      "1  https://fbref.com/en/matches/ed295fea/Atletico...  \n",
      "2  https://fbref.com/en/matches/d5497370/Coritiba...  \n",
      "3  https://fbref.com/en/matches/53471359/Atletico...  \n",
      "4  https://fbref.com/en/matches/f444dd93/Botafogo...  \n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testando a etapa 2 com apenas 1 url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Etapa 2 apenas para 1 url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team 1 fouls: 14, Team 2 fouls: 18, Team 1 corners: 8, Team 2 corners: 1\n",
      "Team 1 shots on target: 6, Team 1 total shots: 26, Team 2 shots on target:  1, Team 2 total shots: 3\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL do primeiro jogo\n",
    "url = \"https://fbref.com/en/matches/9a0d7bad/Fluminense-Santos-April-9-2022-Serie-A\"\n",
    "\n",
    "# Obtenha a página HTML\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Encontre a seção de estatísticas da equipe\n",
    "team_stats = soup.find('div', {'id': 'team_stats_extra'})\n",
    "\n",
    "# Encontre as informações de \"fouls\" e \"corners\"\n",
    "fouls = team_stats.find_all('div', string='Fouls')\n",
    "corners = team_stats.find_all('div', string='Corners')\n",
    "\n",
    "# Extraia os valores para \"fouls\" e \"corners\" para ambos os times\n",
    "for foul, corner in zip(fouls, corners):\n",
    "    team1_fouls = foul.previous_sibling.text\n",
    "    team2_fouls = foul.next_sibling.text\n",
    "    team1_corners = corner.previous_sibling.text\n",
    "    team2_corners = corner.next_sibling.text\n",
    "    print(f\"Team 1 fouls: {team1_fouls}, Team 2 fouls: {team2_fouls}, Team 1 corners: {team1_corners}, Team 2 corners: {team2_corners}\")\n",
    "\n",
    "# Encontre a seção de \"Shots on Target\"\n",
    "shots_on_target_section = soup.find('th', string='Shots on Target').parent.find_next_sibling('tr')\n",
    "\n",
    "# Extraia os valores para \"Shots on Target\" e \"Total Shots\" para ambos os times\n",
    "team1_shots_data = shots_on_target_section.find_all('td')[0].div.div.text\n",
    "team2_shots_data = shots_on_target_section.find_all('td')[1].div.div.text\n",
    "\n",
    "team1_shots_on_target, team1_total_shots = team1_shots_data.split(' of ') if ' of ' in team1_shots_data else (team1_shots_data.split(' ')[0], 'N/A')\n",
    "team2_shots_on_target, team2_total_shots = team2_shots_data.split(' of ') if ' of ' in team2_shots_data else (team2_shots_data.split(' ')[-1], 'N/A')\n",
    "\n",
    "# Pegue apenas os dois primeiros caracteres para 'Team 1 total shots' e os dois últimos para 'Team 2 shots on target'\n",
    "team1_total_shots = team1_total_shots[:2]\n",
    "team2_shots_on_target = team2_shots_on_target[-2:]\n",
    "\n",
    "print(f\"Team 1 shots on target: {team1_shots_on_target}, Team 1 total shots: {team1_total_shots}, Team 2 shots on target: {team2_shots_on_target}, Team 2 total shots: {team2_total_shots}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CÓDIGO COMPLETO E FUNCIONAL ABAIXO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CÓDIGO COMPLETO E FUNCIONAL ABAIXO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CÓDIGO COMPLETO E FUNCIONAL ABAIXO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#filename = 'df_6columns_2022'\n",
    "\n",
    "def save_to_pickle(df, filename):\n",
    "    \"\"\"\n",
    "    Salva um DataFrame em um arquivo pickle.\n",
    "\n",
    "    Parâmetros:\n",
    "    df (pandas.DataFrame): DataFrame para salvar.\n",
    "    filename (str): Nome do arquivo pickle para salvar o DataFrame.\n",
    "    \"\"\"\n",
    "    df.to_pickle(filename + '.pkl')\n",
    "\n",
    "def load_from_pickle(filename):\n",
    "    \"\"\"\n",
    "    Carrega um DataFrame de um arquivo pickle.\n",
    "\n",
    "    Parâmetros:\n",
    "    filename (str): Nome do arquivo pickle para carregar o DataFrame.\n",
    "\n",
    "    Retorna:\n",
    "    pandas.DataFrame: DataFrame carregado do arquivo pickle.\n",
    "    \"\"\"\n",
    "    return pd.read_pickle(filename + '.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Código completo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Etapa 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# INFORMAÇÕES VARIÁVEIS PARA O SITE 'FBREF'\u001b[39;00m\n\u001b[0;32m      3\u001b[0m url \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhttps://fbref.com/en/comps/24/2021/schedule/2021-Serie-A-Scores-and-Fixtures\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m# link da temporada no fbref\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m table \u001b[39m=\u001b[39m soup\u001b[39m.\u001b[39;49mfind(\u001b[39m'\u001b[39;49m\u001b[39mdiv\u001b[39;49m\u001b[39m'\u001b[39;49m, {\u001b[39m'\u001b[39;49m\u001b[39mid\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39mdiv_sched_2021_24_1\u001b[39;49m\u001b[39m'\u001b[39;49m})\u001b[39m.\u001b[39;49mfind(\u001b[39m'\u001b[39m\u001b[39mtable\u001b[39m\u001b[39m'\u001b[39m, {\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39msched_2021_24_1\u001b[39m\u001b[39m'\u001b[39m}) \u001b[39m#usar o inspect e verificar os nomes na tabela geral\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find'"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,1,2,3,4,5,6,7,8,9,11,12,13,14,15,16,17,18,19,20,22,24,25,26,27,28,29,30,31,32,34,35,36,37,38,39,40,41,42,44,45,46,47,48,49,50,51,52,53,55,57,58,59,60,61,62,63,64,65,66,68,69,70,71,72,73,74,75,76,78,79,80,81,82,83,84,85,86,87,89,91,92,93,94,95,96,97,98,99,100,102,103,104,105,106,107,108,109,110,111,113,114,115,116,117,118,119,120,121,122,124,125,126,127,128,129,130,131,132,133,135,136,137,138,139,140,141,142,143,144,146,147,148,149,150,151,152,153,154,155,157,158,159,160,161,162,163,164,165,166,168,169,170,171,172,173,174,175,176,177,179,180,181,182,183,184,185,186,187,188,190,191,192,193,194,195,196,197,198,199,201,202,203,204,205,206,207,208,209,210,212,213,214,215,216,217,218,219,220,221,223,224,225,226,227,228,229,230,231,232,234,235,236,237,238,239,240,241,242,243,245,246,247,248,249,250,251,252,253,254,256,257,258,259,260,261,262,263,264,265,267,268,269,270,271,272,273,274,275,276,278,279,280,281,282,283,284,285,286,287,289,290,291,292,293,294,295,296,297,298,300,301,302,303,304,305,306,307,308,309,311,312,313,314,315,316,317,318,319,321,322,323,324,325,326,327,328,329,330,332,333,334,335,336,337,338,339,340,341,343,344,345,346,347,348,349,350,351,353,355,356,357,358,359,360,361,362,363,364,366,367,368,369,370,371,372,373,374,375,377,379,380,381,382,383,384,385,386,387,388,390,391,392,393,394,395,396,397,398,399,401,402,403,404,405,406,407,408,409,410,412,413,414,415,416,417,418,419,420,421,(380, 6)\n",
      "         date             team1 team1_xg          team2 team2_xg  \\\n",
      "0  2022-04-09        Fluminense      1.6         Santos      0.1   \n",
      "1  2022-04-09    Atl Goianiense      1.4       Flamengo      1.2   \n",
      "2  2022-04-10          Coritiba      1.7          Goiás      0.4   \n",
      "3  2022-04-10  Atlético Mineiro      1.9  Internacional      0.6   \n",
      "4  2022-04-10     Botafogo (RJ)      1.5    Corinthians      2.1   \n",
      "\n",
      "                                    match_report_url  \n",
      "0  https://fbref.com/en/matches/9a0d7bad/Fluminen...  \n",
      "1  https://fbref.com/en/matches/ed295fea/Atletico...  \n",
      "2  https://fbref.com/en/matches/d5497370/Coritiba...  \n",
      "3  https://fbref.com/en/matches/53471359/Atletico...  \n",
      "4  https://fbref.com/en/matches/f444dd93/Botafogo...  \n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "#informações variáveis : \"url\" e \"table\"\n",
    "\n",
    "url = \"https://fbref.com/en/comps/24/2021/schedule/2021-Serie-A-Scores-and-Fixtures\" # link da temporada no fbref\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "table = soup.find('div', {'id': 'div_sched_2021_24_1'}).find('table', {'id': 'sched_2021_24_1'}) #usar o inspect e verificar os nomes na tabela geral\n",
    "tbody = table.find('tbody')\n",
    "\n",
    "# Dicionário para armazenar as informações\n",
    "data = {\n",
    "    'date': [],\n",
    "    'team1': [],\n",
    "    'team1_xg': [],\n",
    "    'team2': [],\n",
    "    'team2_xg': [],\n",
    "    'match_report_url': []\n",
    "}\n",
    "\n",
    "for i, row in enumerate(tbody.find_all('tr')):\n",
    "    date_cell = row.find('td', {'data-stat': 'date'})\n",
    "    if date_cell and date_cell.find('a'):\n",
    "        data['date'].append(date_cell.text)\n",
    "        data['team1'].append(row.find('td', {'data-stat': 'home_team'}).text)\n",
    "        data['team1_xg'].append(row.find('td', {'data-stat': 'home_xg'}).text)\n",
    "        data['team2'].append(row.find('td', {'data-stat': 'away_team'}).text)\n",
    "        data['team2_xg'].append(row.find('td', {'data-stat': 'away_xg'}).text)\n",
    "        match_report_cell = row.find('td', {'data-stat': 'match_report'})\n",
    "        data['match_report_url'].append(\"https://fbref.com\" + match_report_cell.find('a')['href'])\n",
    "        \n",
    "        print(f\"{i},\", end=\"\")\n",
    "        time.sleep(1)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvar o df inicial em um arquivo pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_pickle(df, \"df_6columns_2022\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ler o df em arquivo pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = load_from_pickle(\"df_6columns_2022\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(380, 18)\n",
      "         date             team1 team1_xg          team2 team2_xg  \\\n",
      "0  2022-04-09        Fluminense      1.6         Santos      0.1   \n",
      "1  2022-04-09    Atl Goianiense      1.4       Flamengo      1.2   \n",
      "2  2022-04-10          Coritiba      1.7          Goiás      0.4   \n",
      "3  2022-04-10  Atlético Mineiro      1.9  Internacional      0.6   \n",
      "4  2022-04-10     Botafogo (RJ)      1.5    Corinthians      2.1   \n",
      "\n",
      "                                    match_report_url team1_fouls team2_fouls  \\\n",
      "0  https://fbref.com/en/matches/9a0d7bad/Fluminen...          14          18   \n",
      "1  https://fbref.com/en/matches/ed295fea/Atletico...           7          11   \n",
      "2  https://fbref.com/en/matches/d5497370/Coritiba...          10          12   \n",
      "3  https://fbref.com/en/matches/53471359/Atletico...          12          18   \n",
      "4  https://fbref.com/en/matches/f444dd93/Botafogo...           6          18   \n",
      "\n",
      "  team1_corners team2_corners team1_shots_on_target team1_total_shots  \\\n",
      "0             8             1                     6                26   \n",
      "1             4            10                     3                10   \n",
      "2             7             3                     9                17   \n",
      "3             3             3                     5                15   \n",
      "4             2             4                     3                8    \n",
      "\n",
      "  team2_shots_on_target team2_total_shots  team1_yellow_cards  \\\n",
      "0                     1                 3                   1   \n",
      "1                     3                12                   3   \n",
      "2                     0                 7                   2   \n",
      "3                     1                 6                   2   \n",
      "4                     8                15                   1   \n",
      "\n",
      "   team1_red_cards  team2_yellow_cards  team2_red_cards  \n",
      "0                0                   0                0  \n",
      "1                0                   2                0  \n",
      "2                0                   3                0  \n",
      "3                0                   4                0  \n",
      "4                0                   4                0  \n"
     ]
    }
   ],
   "source": [
    "print(df6.shape)\n",
    "print(df6.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Código para verificar cada saída, caso esteja dando algum erro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Listas para armazenar as novas colunas\n",
    "team1_fouls_list = []\n",
    "team2_fouls_list = []\n",
    "team1_corners_list = []\n",
    "team2_corners_list = []\n",
    "team1_shots_on_target_list = []\n",
    "team1_total_shots_list = []\n",
    "team2_shots_on_target_list = []\n",
    "team2_total_shots_list = []\n",
    "team1_yellow_cards_list = []\n",
    "team1_red_cards_list = []\n",
    "team2_yellow_cards_list = []\n",
    "team2_red_cards_list = []\n",
    "\n",
    "for i, url in enumerate(df6['match_report_url']):\n",
    "    try:\n",
    "        print(f\"Processing URL {url}...\")\n",
    "        response = requests.get(url)\n",
    "        print(\"Got response...\")\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        time.sleep(2)\n",
    "        print(\"Created soup...\")\n",
    "        team_stats = soup.find('div', {'id': 'team_stats_extra'})\n",
    "        #time.sleep(1)\n",
    "        print(\"Found team stats...\")\n",
    "\n",
    "        fouls = team_stats.find_all('div', string='Fouls')\n",
    "        #time.sleep(1)\n",
    "        print(\"Found fouls...\")\n",
    "        corners = team_stats.find_all('div', string='Corners')\n",
    "        #time.sleep(1)\n",
    "        print(\"Found corners...\")\n",
    "\n",
    "        for foul, corner in zip(fouls, corners):\n",
    "            team1_fouls = foul.previous_sibling.text\n",
    "            team2_fouls = foul.next_sibling.text\n",
    "            team1_corners = corner.previous_sibling.text\n",
    "            team2_corners = corner.next_sibling.text\n",
    "\n",
    "        shots_on_target_section = soup.find('th', string='Shots on Target').parent.find_next_sibling('tr')\n",
    "        #time.sleep(1)\n",
    "        print(\"Found shots on target section...\")\n",
    "\n",
    "        team1_shots_data = shots_on_target_section.find_all('td')[0].div.div.text\n",
    "        #time.sleep(1)\n",
    "        print(\"Found team1 shots data...\")\n",
    "        team2_shots_data = shots_on_target_section.find_all('td')[1].div.div.text\n",
    "        #time.sleep(1)\n",
    "        print(\"Found team2 shots data...\")\n",
    "\n",
    "        team1_shots_on_target, team1_total_shots = team1_shots_data.split(' of ') if ' of ' in team1_shots_data else (team1_shots_data.split(' ')[0], 'N/A')\n",
    "        team2_shots_on_target, team2_total_shots = team2_shots_data.split(' of ') if ' of ' in team2_shots_data else (team2_shots_data.split(' ')[-1], 'N/A')\n",
    "\n",
    "        team1_total_shots = team1_total_shots[:2]\n",
    "        team2_shots_on_target = team2_shots_on_target[-2:]\n",
    "\n",
    "        # Encontre a seção de cartões para a equipe 1 e 2\n",
    "        cards_sections = soup.find_all('div', {'class': 'cards'})\n",
    "        print(\"Found cards section for BOTH...\")\n",
    "        cards_section_team1 = cards_sections[0]\n",
    "        #time.sleep(1)\n",
    "        print(\"Found cards section for team1...\")\n",
    "        cards_section_team2 = cards_sections[1]\n",
    "        #time.sleep(1)\n",
    "        print(\"Found cards section for team2...\")\n",
    "        # Encontre todos os cartões amarelos e vermelhos para a equipe 1 e 2\n",
    "        team1_yellow_cards = len(cards_section_team1.find_all('span', {'class': 'yellow_card'})) if cards_section_team1 else np.nan\n",
    "        #time.sleep(1)\n",
    "        print(\"Found yellow cards for team1...\")\n",
    "        team1_red_cards = len(cards_section_team1.find_all('span', {'class': 'red_card'})) if cards_section_team1 else np.nan\n",
    "        #time.sleep(1)\n",
    "        print(\"Found red cards for team1...\")\n",
    "        team2_yellow_cards = len(cards_section_team2.find_all('span', {'class': 'yellow_card'})) if cards_section_team2 else np.nan\n",
    "        #time.sleep(1)\n",
    "        print(\"Found yellow cards for team2...\")\n",
    "        team2_red_cards = len(cards_section_team2.find_all('span', {'class': 'red_card'})) if cards_section_team2 else np.nan\n",
    "        \n",
    "        print(f\"{i}º foi correto!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"{i}ºError processing URL {url}: {e}\")\n",
    "        team1_fouls = np.nan\n",
    "        team2_fouls = np.nan\n",
    "        team1_corners = np.nan\n",
    "        team2_corners = np.nan\n",
    "        team1_shots_on_target = np.nan\n",
    "        team1_total_shots = np.nan\n",
    "        team2_shots_on_target = np.nan\n",
    "        team2_total_shots = np.nan\n",
    "        team1_yellow_cards = np.nan\n",
    "        team1_red_cards = np.nan\n",
    "        team2_yellow_cards = np.nan\n",
    "        team2_red_cards = np.nan\n",
    "\n",
    "    team1_fouls_list.append(team1_fouls)\n",
    "    team2_fouls_list.append(team2_fouls)\n",
    "    team1_corners_list.append(team1_corners)\n",
    "    team2_corners_list.append(team2_corners)\n",
    "    team1_shots_on_target_list.append(team1_shots_on_target)\n",
    "    team1_total_shots_list.append(team1_total_shots)\n",
    "    team2_shots_on_target_list.append(team2_shots_on_target)\n",
    "    team2_total_shots_list.append(team2_total_shots)\n",
    "    team1_yellow_cards_list.append(team1_yellow_cards)\n",
    "    team1_red_cards_list.append(team1_red_cards)\n",
    "    team2_yellow_cards_list.append(team2_yellow_cards)\n",
    "    team2_red_cards_list.append(team2_red_cards)\n",
    "\n",
    "\n",
    "df6['team1_fouls'] = team1_fouls_list\n",
    "df6['team2_fouls'] = team2_fouls_list\n",
    "df6['team1_corners'] = team1_corners_list\n",
    "df6['team2_corners'] = team2_corners_list\n",
    "df6['team1_shots_on_target'] = team1_shots_on_target_list\n",
    "df6['team1_total_shots'] = team1_total_shots_list\n",
    "df6['team2_shots_on_target'] = team2_shots_on_target_list\n",
    "df6['team2_total_shots'] = team2_total_shots_list\n",
    "df6['team1_yellow_cards'] = team1_yellow_cards_list\n",
    "df6['team1_red_cards'] = team1_red_cards_list\n",
    "df6['team2_yellow_cards'] = team2_yellow_cards_list\n",
    "df6['team2_red_cards'] = team2_red_cards_list\n",
    "\n",
    "\n",
    "print(df6.shape)\n",
    "print(df6.head())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemplo da output de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A output seria como:\n",
    "\n",
    "\"\"\"\n",
    ".\n",
    ".\n",
    ".\n",
    "378º foi correto!\n",
    "Processing URL https://fbref.com/en/matches/c5a51ad3/Atletico-Paranaense-Botafogo-RJ-November-13-2022-Serie-A...\n",
    "Got response...\n",
    "Created soup...\n",
    "Found team stats...\n",
    "Found fouls...\n",
    "Found corners...\n",
    "Found shots on target section...\n",
    "Found team1 shots data...\n",
    "Found team2 shots data...\n",
    "Found cards section for BOTH...\n",
    "Found cards section for team1...\n",
    "Found cards section for team2...\n",
    "Found yellow cards for team1...\n",
    "Found red cards for team1...\n",
    "Found yellow cards for team2...\n",
    "379º foi correto!\n",
    "(380, 18)\n",
    "         date             team1 team1_xg          team2 team2_xg  \\\n",
    "0  2022-04-09        Fluminense      1.6         Santos      0.1   \n",
    "1  2022-04-09    Atl Goianiense      1.4       Flamengo      1.2   \n",
    "2  2022-04-10          Coritiba      1.7          Goiás      0.4   \n",
    "3  2022-04-10  Atlético Mineiro      1.9  Internacional      0.6   \n",
    "4  2022-04-10     Botafogo (RJ)      1.5    Corinthians      2.1   \n",
    "\n",
    "                                    match_report_url team1_fouls team2_fouls  \\\n",
    "0  https://fbref.com/en/matches/9a0d7bad/Fluminen...          14          18   \n",
    "1  https://fbref.com/en/matches/ed295fea/Atletico...           7          11   \n",
    "2  https://fbref.com/en/matches/d5497370/Coritiba...          10          12   \n",
    "3  https://fbref.com/en/matches/53471359/Atletico...          12          18   \n",
    "4  https://fbref.com/en/matches/f444dd93/Botafogo...           6          18   \n",
    "\n",
    "  team1_corners team2_corners team1_shots_on_target team1_total_shots  \\\n",
    "0             8             1                     6                26   \n",
    "1             4            10                     3                10   \n",
    "2             7             3                     9                17   \n",
    "3             3             3                     5                15   \n",
    "4             2             4                     3                8    \n",
    "\n",
    "  team2_shots_on_target team2_total_shots  team1_yellow_cards  \\\n",
    "0                     1                 3                   1   \n",
    "1                     3                12                   3   \n",
    "2                     0                 7                   2   \n",
    "3                     1                 6                   2   \n",
    "4                     8                15                   1   \n",
    "\n",
    "   team1_red_cards  team2_yellow_cards  team2_red_cards  \n",
    "0                0                   0                0  \n",
    "1                0                   2                0  \n",
    "2                0                   3                0  \n",
    "3                0                   4                0  \n",
    "4                0                   4                0  \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Código que calcula direto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listas para armazenar as novas colunas\n",
    "team1_fouls_list = []\n",
    "team2_fouls_list = []\n",
    "team1_corners_list = []\n",
    "team2_corners_list = []\n",
    "team1_shots_on_target_list = []\n",
    "team1_total_shots_list = []\n",
    "team2_shots_on_target_list = []\n",
    "team2_total_shots_list = []\n",
    "team1_yellow_cards_list = []\n",
    "team1_red_cards_list = []\n",
    "team2_yellow_cards_list = []\n",
    "team2_red_cards_list = []\n",
    "\n",
    "for i, url in enumerate(df6['match_report_url']):\n",
    "    try:\n",
    "        print(f\"Processing URL {url}...\")\n",
    "        response = requests.get(url)\n",
    "        print(\"Got response...\")\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        time.sleep(2)\n",
    "        print(\"Created soup...\")\n",
    "        team_stats = soup.find('div', {'id': 'team_stats_extra'})\n",
    "        #time.sleep(1)\n",
    "        print(\"Found team stats...\")\n",
    "\n",
    "        fouls = team_stats.find_all('div', string='Fouls')\n",
    "        #time.sleep(1)\n",
    "        print(\"Found fouls...\")\n",
    "        corners = team_stats.find_all('div', string='Corners')\n",
    "        #time.sleep(1)\n",
    "        print(\"Found corners...\")\n",
    "\n",
    "        for foul, corner in zip(fouls, corners):\n",
    "            team1_fouls = foul.previous_sibling.text\n",
    "            team2_fouls = foul.next_sibling.text\n",
    "            team1_corners = corner.previous_sibling.text\n",
    "            team2_corners = corner.next_sibling.text\n",
    "\n",
    "        shots_on_target_section = soup.find('th', string='Shots on Target').parent.find_next_sibling('tr')\n",
    "        #time.sleep(1)\n",
    "        print(\"Found shots on target section...\")\n",
    "\n",
    "        team1_shots_data = shots_on_target_section.find_all('td')[0].div.div.text\n",
    "        #time.sleep(1)\n",
    "        print(\"Found team1 shots data...\")\n",
    "        team2_shots_data = shots_on_target_section.find_all('td')[1].div.div.text\n",
    "        #time.sleep(1)\n",
    "        print(\"Found team2 shots data...\")\n",
    "\n",
    "        team1_shots_on_target, team1_total_shots = team1_shots_data.split(' of ') if ' of ' in team1_shots_data else (team1_shots_data.split(' ')[0], 'N/A')\n",
    "        team2_shots_on_target, team2_total_shots = team2_shots_data.split(' of ') if ' of ' in team2_shots_data else (team2_shots_data.split(' ')[-1], 'N/A')\n",
    "\n",
    "        team1_total_shots = team1_total_shots[:2]\n",
    "        team2_shots_on_target = team2_shots_on_target[-2:]\n",
    "\n",
    "        # Encontre a seção de cartões para a equipe 1 e 2\n",
    "        cards_sections = soup.find_all('div', {'class': 'cards'})\n",
    "        print(\"Found cards section for BOTH...\")\n",
    "        cards_section_team1 = cards_sections[0]\n",
    "        #time.sleep(1)\n",
    "        print(\"Found cards section for team1...\")\n",
    "        cards_section_team2 = cards_sections[1]\n",
    "        #time.sleep(1)\n",
    "        print(\"Found cards section for team2...\")\n",
    "        # Encontre todos os cartões amarelos e vermelhos para a equipe 1 e 2\n",
    "        team1_yellow_cards = len(cards_section_team1.find_all('span', {'class': 'yellow_card'})) if cards_section_team1 else np.nan\n",
    "        #time.sleep(1)\n",
    "        print(\"Found yellow cards for team1...\")\n",
    "        team1_red_cards = len(cards_section_team1.find_all('span', {'class': 'red_card'})) if cards_section_team1 else np.nan\n",
    "        #time.sleep(1)\n",
    "        print(\"Found red cards for team1...\")\n",
    "        team2_yellow_cards = len(cards_section_team2.find_all('span', {'class': 'yellow_card'})) if cards_section_team2 else np.nan\n",
    "        #time.sleep(1)\n",
    "        print(\"Found yellow cards for team2...\")\n",
    "        team2_red_cards = len(cards_section_team2.find_all('span', {'class': 'red_card'})) if cards_section_team2 else np.nan\n",
    "        \n",
    "        print(f\"{i}º foi correto!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"{i}ºError processing URL {url}: {e}\")\n",
    "        team1_fouls = np.nan\n",
    "        team2_fouls = np.nan\n",
    "        team1_corners = np.nan\n",
    "        team2_corners = np.nan\n",
    "        team1_shots_on_target = np.nan\n",
    "        team1_total_shots = np.nan\n",
    "        team2_shots_on_target = np.nan\n",
    "        team2_total_shots = np.nan\n",
    "        team1_yellow_cards = np.nan\n",
    "        team1_red_cards = np.nan\n",
    "        team2_yellow_cards = np.nan\n",
    "        team2_red_cards = np.nan\n",
    "\n",
    "    team1_fouls_list.append(team1_fouls)\n",
    "    team2_fouls_list.append(team2_fouls)\n",
    "    team1_corners_list.append(team1_corners)\n",
    "    team2_corners_list.append(team2_corners)\n",
    "    team1_shots_on_target_list.append(team1_shots_on_target)\n",
    "    team1_total_shots_list.append(team1_total_shots)\n",
    "    team2_shots_on_target_list.append(team2_shots_on_target)\n",
    "    team2_total_shots_list.append(team2_total_shots)\n",
    "    team1_yellow_cards_list.append(team1_yellow_cards)\n",
    "    team1_red_cards_list.append(team1_red_cards)\n",
    "    team2_yellow_cards_list.append(team2_yellow_cards)\n",
    "    team2_red_cards_list.append(team2_red_cards)\n",
    "\n",
    "\n",
    "df6['team1_fouls'] = team1_fouls_list\n",
    "df6['team2_fouls'] = team2_fouls_list\n",
    "df6['team1_corners'] = team1_corners_list\n",
    "df6['team2_corners'] = team2_corners_list\n",
    "df6['team1_shots_on_target'] = team1_shots_on_target_list\n",
    "df6['team1_total_shots'] = team1_total_shots_list\n",
    "df6['team2_shots_on_target'] = team2_shots_on_target_list\n",
    "df6['team2_total_shots'] = team2_total_shots_list\n",
    "df6['team1_yellow_cards'] = team1_yellow_cards_list\n",
    "df6['team1_red_cards'] = team1_red_cards_list\n",
    "df6['team2_yellow_cards'] = team2_yellow_cards_list\n",
    "df6['team2_red_cards'] = team2_red_cards_list\n",
    "\n",
    "\n",
    "print(df6.shape)\n",
    "print(df6.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificando a quantidade de NaN em cada coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date                     0\n",
      "team1                    0\n",
      "team1_xg                 0\n",
      "team2                    0\n",
      "team2_xg                 0\n",
      "match_report_url         0\n",
      "team1_fouls              0\n",
      "team2_fouls              0\n",
      "team1_corners            0\n",
      "team2_corners            0\n",
      "team1_shots_on_target    0\n",
      "team1_total_shots        0\n",
      "team2_shots_on_target    0\n",
      "team2_total_shots        0\n",
      "team1_yellow_cards       0\n",
      "team1_red_cards          0\n",
      "team2_yellow_cards       0\n",
      "team2_red_cards          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "nan_counts = df6.isna().sum()\n",
    "print(nan_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertendo as colunas certas para float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6['date'] = pd.to_datetime(df6['date'])\n",
    "df6['date'] = df6['date'].dt.strftime('%d/%m/%Y')\n",
    "df6['team1_xg'] = df6['team1_xg'].fillna(0).astype('float64')\n",
    "df6['team2_xg'] = df6['team2_xg'].fillna(0).astype('float64')\n",
    "df6['team1_fouls'] = df6['team1_fouls'].fillna(0).astype('float64')\n",
    "df6['team2_fouls'] = df6['team2_fouls'].fillna(0).astype('float64')\n",
    "df6['team1_corners'] = df6['team1_corners'].fillna(0).astype('float64')\n",
    "df6['team2_corners'] = df6['team2_corners'].fillna(0).astype('float64')\n",
    "df6['team1_shots_on_target'] = df6['team1_shots_on_target'].fillna(0).astype('float64')\n",
    "df6['team1_total_shots'] = df6['team1_total_shots'].fillna(0).astype('float64')\n",
    "df6['team2_shots_on_target'] = df6['team2_shots_on_target'].fillna(0).astype('float64')\n",
    "df6['team2_total_shots'] = df6['team2_total_shots'].fillna(0).astype('float64')\n",
    "df6['team1_yellow_cards'] = df6['team1_yellow_cards'].fillna(0).astype('float64')\n",
    "df6['team1_red_cards'] = df6['team1_red_cards'].fillna(0).astype('float64')\n",
    "df6['team2_yellow_cards'] = df6['team2_yellow_cards'].fillna(0).astype('float64')\n",
    "df6['team2_red_cards'] = df6['team2_red_cards'].fillna(0).astype('float64')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificando os types de cada coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                      object\n",
       "team1                     object\n",
       "team1_xg                 float64\n",
       "team2                     object\n",
       "team2_xg                 float64\n",
       "match_report_url          object\n",
       "team1_fouls              float64\n",
       "team2_fouls              float64\n",
       "team1_corners            float64\n",
       "team2_corners            float64\n",
       "team1_shots_on_target    float64\n",
       "team1_total_shots        float64\n",
       "team2_shots_on_target    float64\n",
       "team2_total_shots        float64\n",
       "team1_yellow_cards       float64\n",
       "team1_red_cards          float64\n",
       "team2_yellow_cards       float64\n",
       "team2_red_cards          float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df6).dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando o excel desta temporada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6.to_excel(\"df6_2022.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
